# Git's ORT Merge Strategy: Deep Implementation Analysis

Git's ORT (Ostensibly Recursive's Twin) merge strategy represents a complete architectural reimplementation of merge operations, delivering **500-9000x performance improvements** while fixing fundamental correctness issues in the legacy recursive strategy. Developed by Elijah Newren and made default in Git 2.34 (November 2021), ORT performs all merge operations in-memory using sophisticated data structures and deferred computation, only touching the working tree and index as a final post-processing step. The implementation spans approximately 5,000 lines in merge-ort.c, utilizing memory pools, string maps, and bit-masked state tracking to achieve unprecedented performance in repositories with extensive rename activity.

The fundamental innovation lies in separating merge computation from filesystem updates. Where recursive merge incrementally updated the index and working tree during traversal, ORT builds a complete in-memory representation first, enabling computation reuse across sequential merges (critical for rebases), intelligent deferred directory traversal, and efficient rename detection caching. This architectural shift eliminates the primary performance bottlenecks while simultaneously fixing edge cases involving directory/file conflicts, transitive renames, and complex merge scenarios.

## Core data structures powering the algorithm

The ORT implementation revolves around several interconnected data structures that maintain merge state entirely in memory until the final checkout phase.

**The merge_options_internal structure** serves as the central repository for all merge state. Its `paths` field is a strmap (string map) that maps every relevant pathname to either a `merged_info` or `conflict_info` structure, providing O(1) lookup performance. The `conflicted` strmap maintains a separate index into only conflicted paths for efficient conflict processing. The `pool` field references a `mem_pool` structure that batch-allocates memory for path strings and metadata, dramatically reducing malloc/free overhead and improving cache locality. The `renames` field contains a `rename_info` structure housing all rename detection state, while `current_dir_name` tracks position during tree traversal.

**The conflict_info structure** represents the heart of ORT's conflict tracking mechanism. It embeds a `merged_info` structure and extends it with an array of three `version_info` structures representing BASE, SIDE1, and SIDE2 versions. Three critical bit fields encode conflict state: `filemask` (3 bits) indicates which sides have this path as a file, `dirmask` (3 bits) shows which sides have it as a directory, and `match_mask` (3 bits) tracks which pairs of versions have identical content. When filemask and dirmask both have non-zero bits, a directory/file conflict exists. The structure also maintains separate pathnames for each stage since rename detection may cause paths to differ across versions.

**The version_info structure** encapsulates file metadata with just two fields: an `object_id` (Git's SHA-1 or SHA-256 hash) and an unsigned short `mode` representing Unix file permissions. This minimal representation enables efficient comparison and storage while providing all information needed for three-way merge operations.

**The rename_info structure** manages the complex state required for rename detection. It maintains `pairs[3]` arrays storing detected rename pairs for each merge side, `relevant_sources[3]` strintmaps tracking which source files need rename consideration (categorized by `enum file_rename_relevance`), and crucially, `cached_pairs[2]` and `cached_irrelevant[2]` structures that preserve rename detection results across sequential merges. For directory rename detection, it uses `dir_rename_count[3]` strmaps-of-strmaps tracking how many files moved from each old directory to each new directory, and `dir_rename_guess[3]` storing the best guess for where each directory was renamed. The `deferred[3]` fields contain `deferred_traversal_data` structures enabling lazy directory processing when optimization is possible.

**The traversal_callback_data structure** facilitates tree traversal by collecting information during the three-way tree walk. It maintains `mask` and `dirmask` unsigned longs indicating which trees contain entries at the current path, plus a `name_entry` array with details from all three trees. This structure feeds the `collect_merge_info_callback()` function that populates the paths map during traversal.

**The merge_result structure** provides the public API contract for merge operations. It contains a `clean` integer (1 for successful merge, 0 for conflicts), a `tree` pointer to the resulting Git tree object, a `path_messages` strmap containing conflict and warning messages organized by path, and a `priv` pointer to private implementation details that users should not access directly.

## Algorithm execution phases from initialization to completion

ORT's merge algorithm proceeds through seven distinct phases, each with specific responsibilities and optimizations.

**Phase 1: Initialization via merge_start()** allocates the `merge_options_internal` structure and initializes its memory pool using `mem_pool_init()` with a zero size hint, allowing dynamic growth. It calls `strmap_init_with_options()` to create the paths strmap with `strdup_strings = 0` for efficiency, since the memory pool manages string lifetimes. Rename detection structures are initialized with `strintmap_init_with_options()` for `dirs_removed` and `strmap_init_with_options()` for `dir_rename_count` and `dir_renames`. Critically, this phase sets the default diff algorithm to histogram using `DIFF_WITH_ALG(opt, HISTOGRAM_DIFF)`, which cannot be overridden by user configuration. The attribute direction for renormalization is configured based on which direction the merge flows.

**Phase 2: Tree traversal in collect_merge_info()** performs a simultaneous three-way walk through the merge base, side1, and side2 trees using Git's `traverse_trees()` function. For each path encountered, it calls `collect_merge_info_callback()` which computes filemask and dirmask values using bitwise operations: `filemask |= (1 << side)` for each side that has a file at this path. The callback invokes `setup_path_info()` to create either `merged_info` structures for cleanly resolved paths or `conflict_info` structures for paths requiring further analysis. The algorithm handles special cases including files present on all sides (requiring three-way merge), files added on one side only (trivial resolution), files deleted on one side (modify/delete conflict), and directory/file conflicts detected when both filemask and dirmask are non-zero. For optimization, ORT implements deferred directory traversal: when a directory is unchanged on one side, it calls `resolve_trivial_directory_merge()` to handle it without recursing into every file.

**Phase 3: Rename detection through detect_and_process_renames()** orchestrates the sophisticated rename detection system. The function first calls `detect_regular_renames()` which interfaces with `diffcore_rename_extended()` from diffcore-rename.c to perform actual similarity detection. The process begins with exact hash matching (O(1) lookups comparing object IDs), then applies basename matching as an optimization (files with identical basenames are strong rename candidates), and finally performs inexact matching using `estimate_similarity()` only when necessary. This function calculates a similarity score by calling `diffcore_count_changes()` to count insertions and deletions, then computes `(src_copied * MAX_SCORE / max_size)` with early exit optimization if `delta_size * MAX_SCORE > max_size * (MAX_SCORE - minimum_score)`. Directory rename detection runs in three phases: counting phase calls `update_dir_rename_counts()` to increment counters for each file rename pattern, aggregation phase runs `compute_dir_rename_guess()` to find the new directory with highest count for each old directory, and application phase executes `apply_directory_rename_modifications()` to transitively apply directory renames to files added on one side.

**Phase 4: Content merging in process_entries()** iterates through all paths in the paths strmap in sorted order, invoking `process_entry()` for each. This central dispatch function examines the filemask and match_mask to determine conflict type. For clean merges where all sides match or only one side modified the file, it calls `record_entry_for_tree()` to stage the result. For content conflicts, it invokes `handle_content_merge()` which performs the actual three-way merge by reading blob contents from all three sides and calling `xdl_merge()` from the xdiff library. The function `merge_3way()` handles the core three-way merge implementation, including special handling for binary files and producing merged content with conflict markers when automatic resolution fails. Modify/delete conflicts are processed by `handle_modify_delete()`, rename/delete conflicts by checking pathname differences, directory/file conflicts through explicit df_conflict checking, and type changes (symlink to regular file, etc.) through mode comparison.

**Phase 5: Conflict resolution and message generation** uses `path_msg()` to record conflict messages for each affected path, storing them in a strmap for later batch output. The function `handle_file_collision()` manages files that collide due to renames, while `unique_path()` generates unique pathnames for conflicted entries that must coexist in the working tree. ORT tracks multiple conflict types using symbolic constants: CONFLICT_MODIFY_DELETE when a file is modified on one side and deleted on the other, CONFLICT_RENAME_DELETE when renaming and deletion conflict, CONFLICT_DIR_RENAME_FILE_IN_WAY when a directory rename is blocked by an existing file at the target location, CONFLICT_DIR_RENAME_COLLISION when a directory is renamed to multiple different locations, CONFLICT_CONTENTS for standard content conflicts, CONFLICT_SUBMODULE for submodule pointer conflicts, and CONFLICT_BINARY for binary file conflicts that cannot be auto-merged.

**Phase 6: Tree construction using write_tree()** builds the result tree bottom-up from leaves to root. The function `write_completed_directory()` recursively writes directory trees, while `record_entry_for_tree()` adds clean entries to the appropriate position in the tree structure. ORT uses a `dir_metadata` structure to track directory construction state, ensuring proper hierarchical organization. The algorithm creates Git tree objects with computed object IDs representing the merged state.

**Phase 7: Index and worktree update via merge_switch_to_result()** finally touches the filesystem as a post-processing step. The `checkout()` function updates the working tree using Git's `unpack_trees()` machinery, while `record_unmerged_index_entries()` writes conflicted entries to the index with appropriate stage numbers (stage 0 for clean files, stage 1 for merge base version, stage 2 for "ours", stage 3 for "theirs"). The `update_index()` function completes index updates with merge results, handling file mode changes and creating working tree files with conflict markers when necessary. ORT also creates an AUTO_MERGE reference pointing to a tree containing the current working tree content including conflict markers, enabling easier conflict recovery.

## Key optimizations delivering dramatic speedups

ORT achieves its remarkable performance through several carefully designed optimizations that work synergistically.

**Memory pool allocation** eliminates the malloc/free overhead that plagued recursive merge. The `mem_pool` structure batch-allocates memory for frequently-created structures like path strings and metadata objects. All allocations during the merge come from this pool, which is freed in a single operation at merge completion. This approach improves cache locality since related objects are allocated contiguously, reduces memory fragmentation, and eliminates thousands of individual free() calls. Wrapper functions like `pool_alloc()`, `pool_calloc()`, and `pool_strndup()` provide convenient interfaces to pool allocation, with fallback to regular malloc when no pool is available.

**String interning via strmap** stores each path string exactly once in the paths strmap, enabling pointer comparison instead of expensive `strcmp()` calls. Since paths are stored as keys in the strmap, looking up path information becomes O(1) hash table lookup rather than linear search or repeated string duplication. This optimization becomes increasingly important as repository size grows, providing significant performance gains for repositories with thousands of files.

**Histogram diff algorithm** is mandated as the default in ORT through `opt->xdl_opts = DIFF_WITH_ALG(opt, HISTOGRAM_DIFF)`. Unlike the Myers algorithm used by default in recursive merge, histogram performs better on typical code changes by identifying low-occurrence common elements more accurately. This reduces spurious conflicts and improves rename detection quality. While histogram has slightly higher computational complexity, it generally runs faster on real-world code due to better branch prediction and fewer false matches.

**Deferred directory traversal** represents one of ORT's most impactful optimizations. The algorithm checks whether a directory is unchanged on one side by comparing tree object IDs. When a directory's tree ID matches between base and one side, ORT can resolve it without recursing into every file, instead taking the other side's directory tree wholesale. The `dir_rename_mask` field controls this optimization with values: 0 indicates optimization is fully safe, 2 or 4 means optimization is okay but must check for added files, and 7 forbids optimization because rename sources are needed for directory rename detection. The `deferred_traversal_data` structure tracks `possible_trivial_merges` (directories that might not need recursion) and `trivial_merges_okay` flag indicating whether optimization is valid for the current path.

**Rename detection caching** enables dramatic speedups for sequential merge operations like rebases and cherry-picks. ORT's `cached_pairs[side]` arrays preserve rename pairs from previous merges, while `cached_irrelevant[side]` strsets track files marked irrelevant. When performing a subsequent merge, ORT only re-runs rename detection for newly relevant paths or paths with different tree OIDs than cached. Since rebases often have consistent renames across multiple commits (the upstream side typically has stable rename patterns), this caching delivers the 9000x speedups measured in worst-case scenarios. The `merge_trees` field tracks which trees were involved to validate cache consistency.

**Basename prefetching** optimizes rename detection by checking for exact OID matches first (hash-based O(1) comparison), then basename matches (file renamed within same directory or to similar location), and only then performing expensive content similarity detection. The `basename_prefetch()` function fetches blobs for files with matching basenames before running full inexact detection, while `inexact_prefetch()` handles remaining cases. For partial clone users, this optimization reduces object fetches by 181.3x in some scenarios by avoiding unnecessary downloads of blob contents.

**Relevance filtering** significantly reduces rename detection workload. The algorithm precomputes which source files need rename consideration through `collect_rename_info()`, categorizing them by `enum file_rename_relevance`: RELEVANT_NO_MORE (0) for previously relevant but no longer needed files, RELEVANT_CONTENT (1) for files modified on the other side, and RELEVANT_LOCATION (2) for files in directories modified on the other side. By skipping irrelevant renames (those not modified on the other side), ORT reduces the comparison space from potentially millions of file pairs to just thousands in typical merges.

## Fundamental differences from the recursive merge strategy

The transition from recursive to ORT represents a complete algorithmic and architectural redesign, not merely an optimization of the existing approach.

**Operational model** differs fundamentally between strategies. Recursive merge operated primarily on Git's index (the staging area stored on disk) and working tree, requiring a fully populated checkout to perform merges and making incremental updates throughout the merge process. This made it difficult to use merge as a library function and impossible to perform server-side merges without temporary working directories. ORT performs all operations in-memory without touching the working tree or index until the final checkout phase, enabling merges between any two branches regardless of current checkout state and facilitating server-side merge operations without disk I/O overhead.

**Data structure organization** reveals the depth of the redesign. Recursive merge used linked lists and Git's index structure (essentially an on-disk format) for tracking merge state, requiring repeated index file reads/writes and making cache locality poor. ORT uses modern data structures: strmap for O(1) path lookups, memory pools for allocation efficiency, and bit fields for compact state representation. The paths strmap provides direct access to any file's merge state, while recursive required linear search or repeated index queries.

**Rename detection** always runs in ORT and cannot be disabled with the `no-renames` option (which recursive respected). ORT's rename detection uses histogram diff by default and implements sophisticated caching via `cached_pairs` arrays, reusing detection results across sequential merges. Recursive ran rename detection optionally, used whatever diff algorithm the user configured (defaulting to Myers), and recomputed renames for every merge operation. The performance difference is stark: recursive's mega-renames testcase took 5,964 seconds while ORT completed it in 661.8 milliseconds (9,012x speedup).

**Tree traversal strategy** demonstrates ORT's optimization focus. ORT implements deferred directory traversal through `deferred_traversal_data` structures, checking if directories are unchanged on one side and resolving them without recursing into every file. Recursive always recursed into all directories, performing complete tree walks even for unchanged portions. ORT also avoids repeating `fill_tree_descriptor()` on the same tree and skips traversing into identical trees, benefiting users with partial clones by reducing object fetches.

**Conflict handling** shows improved user experience design. ORT defers message printing until processing completes, allowing all messages about a path to be grouped together through the `path_msg()` queuing system. This provides clearer output than recursive's incremental message printing. ORT creates an AUTO_MERGE reference pointing to a tree with conflict markers, enabling easier conflict inspection and recovery. Recursive did not create this reference. ORT's `conflict_info` structure provides richer metadata about conflict types through explicit filemask, dirmask, and df_conflict tracking.

**Performance characteristics** reveal the optimization impact. Benchmarks from Elijah Newren show consistent improvements: the few-renames testcase improved from 18.9 seconds to 198 milliseconds (95x speedup), mega-renames from 5,964 seconds to 661.8 milliseconds (9,012x speedup), and just-one-mega from 149.6 seconds to 264.6 milliseconds (565x speedup). GitHub reported 10x speedups for average merges and 5-10x for P99 cases when switching their monorepo to ORT. Most importantly, ORT exhibits consistent performance with low variance, while recursive had occasional catastrophically slow merges.

**Code maintainability** improves substantially with ORT's clean separation of concerns. The from-scratch implementation spans approximately 5,000 lines in merge-ort.c with clear phase separation (initialization, traversal, rename detection, content merge, conflict resolution, tree construction, filesystem update). Recursive's code had accumulated complexity from years of incremental fixes, making it difficult to optimize or extend. ORT's cleaner architecture enabled new features like remerge-diff (showing differences between automatic merge results and committed merges) and improved server-side merge capabilities.

## Rename detection implementation at the algorithm level

ORT's rename detection system combines exact matching, basename heuristics, content similarity analysis, and directory-level pattern recognition to achieve both accuracy and performance.

**The detection pipeline** begins with `collect_rename_info()` gathering information during tree traversal about potential renames. It updates `dir_rename_mask` values to determine when directory rename detection is needed and populates the `relevant_sources` strintmaps. The main orchestrator `detect_and_process_renames()` checks if rename detection is needed by examining `needed_limit` and calls into `diffcore_rename_extended()` from diffcore-rename.c.

**Exact matching** provides the fastest path for renamed files with unchanged content. The algorithm compares object IDs (SHA-1 or SHA-256 hashes) between deleted files on one side and added files on the other side. Since hash comparison is O(1), this phase identifies many renames instantly without examining file contents. Files matched this way bypass all subsequent detection phases.

**Basename matching** serves as an optimization between exact and inexact matching. Files with identical basenames are strong candidates for renames, especially when renamed within the same directory or to a similar location. The `basename_prefetch()` function fetches blob contents for files with matching basenames before running full inexact detection, reducing latency for partial clones. This heuristic catches common cases like moving files between related directories (src/utils → lib/utils) without expensive content comparison.

**Inexact similarity detection** handles renames with content modifications. The `estimate_similarity()` function calculates a similarity score between source and destination files by calling `diffcore_count_changes()` to count insertions and deletions. The score is computed as `(src_copied * MAX_SCORE / max_size)` where `src_copied` represents the number of unchanged lines. An early exit optimization terminates comparison if `delta_size * MAX_SCORE > max_size * (MAX_SCORE - minimum_score)`, avoiding pointless analysis when files are clearly too different. The default similarity threshold is 50%, meaning at least half the content must match for a rename to be detected.

**Directory rename detection** operates at a higher semantic level by recognizing patterns across multiple file renames. The three-phase algorithm begins with the counting phase where `update_dir_rename_counts()` examines each detected file rename (src/X → dst/Y) and increments a counter: `dir_rename_count[src][dst]++`. This builds a nested strmap structure mapping old directories to new directories to occurrence counts. The aggregation phase calls `compute_dir_rename_guess()` to identify the new directory with the highest count for each old directory, storing results in `dir_rename_guess[old_dir] = best_new_dir`. The application phase executes `apply_directory_rename_modifications()` to transitively apply directory renames: when a file is added to old_dir on one side and the directory was renamed to new_dir on the other side, the file's path is updated to new_dir/filename.

**Transitive rename prevention** handles complex scenarios where naive directory rename application would produce incorrect results. Consider the case where side1 renames A→B and side2 renames B→C. Without prevention, ORT might incorrectly conclude A→C. The algorithm tracks rename chains and prevents doubly transitive renames that could cause assertion failures or silent mismerges. This represents a correctness improvement over recursive merge which had bugs in this area.

**Relevance categorization** dramatically reduces computational overhead by limiting which source files need rename detection. The `relevant_sources` strintmap categorizes files using `enum file_rename_relevance` values: RELEVANT_NO_MORE (0) indicates files previously relevant but no longer needed, RELEVANT_CONTENT (1) marks files modified on the other side (the most important category since merging these renames with modifications requires three-way content merge), and RELEVANT_LOCATION (2) identifies files in directories modified on the other side. By skipping irrelevant renames, ORT reduces comparison operations from potentially millions to thousands in typical scenarios.

**Caching across sequential merges** leverages the observation that rebases and cherry-pick sequences often have consistent rename patterns on the upstream side. The `cached_pairs[side]` arrays preserve rename pairs from the previous merge, while `cached_irrelevant[side]` strsets track files marked irrelevant. The `merge_trees` field stores which trees were involved to validate cache consistency. When performing a subsequent merge, ORT checks if the merge_trees match cached values and if so, only re-runs detection for newly relevant paths or paths with different tree OIDs. This caching mechanism enables the 9,012x speedup measured in the mega-renames testcase, where a rebase performing 50 sequential merges benefits from rename detection running once and being reused 49 times.

## Directory/file conflict handling and resolution

Directory/file conflicts occur when a path exists as a directory on one branch and a file on another, requiring careful resolution to preserve both entities in the working tree.

**Detection mechanism** uses the filemask and dirmask bit fields in `conflict_info` structures. Each field is a 3-bit value where bit positions represent merge sides: bit 0 for base, bit 1 for side1, bit 2 for side2. When both `filemask` and `dirmask` are non-zero (checked via `filemask & dirmask != 0`), a directory/file conflict exists at this path. The `df_conflict` boolean flag is set to 1 to mark this condition explicitly.

**Resolution strategy** preserves both the directory contents and the file when possible. The directory remains at its original path since moving it would affect all files within. The file is either staged at a higher stage number in the index or moved to a unique path generated by the `unique_path()` function. This might produce paths like `filename~HEAD` or `filename~branch_name` to avoid collisions. The working tree contains both entities after merge completion, allowing users to examine both and decide which to keep.

**Index staging** for directory/file conflicts uses Git's multi-stage mechanism. The file version from one side is staged at stage 2 (ours) or stage 3 (theirs) depending on which side has the file. The directory contents are staged normally at stage 0 since they don't conflict with themselves. The `record_unmerged_index_entries()` function handles this staging during the final update phase. Examining the index with `git ls-files -u` reveals the staged entries showing the conflict state.

**Special case handling** includes scenarios where a directory is converted to a file (side1 removes directory and creates file at same path, side2 modifies directory contents). ORT stages this as a standard directory/file conflict with appropriate conflict messages. The inverse case (file converted to directory) is handled symmetrically. When directory renames interact with directory/file conflicts, ORT generates `CONFLICT_DIR_RENAME_FILE_IN_WAY` messages indicating that a directory rename was blocked by an existing file at the target location.

**Conflict messages** are queued through `path_msg()` with the conflict type set to `CONFLICT_DIR_RENAME_FILE_IN_WAY` or similar constants. These messages are displayed to users during `merge_display_update_messages()` in the final phase, grouped by path for clarity. The AUTO_MERGE reference created by ORT points to a tree reflecting the conflict state, enabling users to inspect or reset to it if needed.

## Tree traversal mechanics and optimization techniques

ORT's tree traversal system builds a complete in-memory representation of the merge state before any processing, enabling powerful optimizations unavailable to recursive merge's interleaved traversal-and-processing approach.

**The traversal infrastructure** uses Git's `traverse_trees()` function to simultaneously walk three trees: merge base, side1, and side2. The callback function `collect_merge_info_callback()` receives information about each path through a `traversal_callback_data` structure containing `mask` (which trees have entries), `dirmask` (which trees have directories), and `names[3]` (name_entry structures from each tree). This callback populates the paths strmap with initial merge state.

**Path information creation** happens through `setup_path_info()` which receives the current directory name, path length, full path string, name entries from all three trees, and computed filemask/dirmask values. It allocates a new `merged_info` or `conflict_info` structure from the memory pool and initializes it with appropriate values. The `basename_offset` field is set to enable efficient basename extraction without string manipulation. For trivially resolvable paths (identical on all sides or changed on only one side), the merged result is computed immediately.

**Deferred directory traversal** provides major performance gains by avoiding recursion into unchanged directories. The algorithm compares tree object IDs between base and each side. When a directory's tree ID matches between base and side1, the entire directory is unchanged on side1, so ORT can take side2's directory tree wholesale by calling `resolve_trivial_directory_merge()`. This function sets `match_mask` to indicate the matching sides, copies the appropriate tree OID to the result, and marks the merge as clean without recursing. The `deferred_traversal_data` structure tracks directories where this optimization might apply, deferring the recursion decision until rename detection completes.

**The dir_rename_mask optimization** controls whether certain rename-related optimizations are safe. A value of 0 indicates that removing unmodified potential rename sources is safe (directory definitely not renamed). Values of 2 or 4 mean optimization is okay but the algorithm must check for files added to the directory. A value of 7 forbids optimization because rename sources are needed for directory rename detection. This field is computed during initial traversal and influences whether `collect_merge_info_callback()` can take optimization shortcuts.

**Wrapper traversal** implements a two-pass approach when directory renames are possible. The `traverse_trees_wrapper()` function first processes all files before descending into subdirectories, enabling better rename detection by ensuring files are visible before directory rename patterns are computed. This contrasts with the simple traversal that processes entries in tree order, which might compute directory renames before seeing all relevant files.

**Trivial merge resolution** handles cases where all three sides have identical content or only one side modified the file. The algorithm checks if `match_mask == 7` (all sides match) or if only one side differs from the base. For these cases, `record_entry_for_tree()` is called immediately to stage the result without invoking content merge machinery. This avoids thousands of unnecessary `xdl_merge()` calls in typical merges where most files are unchanged.

**Memory efficiency** is achieved through the memory pool allocation strategy where all path strings, conflict_info structures, and auxiliary data are allocated from the pool and freed together. The paths strmap uses `strdup_strings = 0` mode, meaning it doesn't duplicate path strings since they're already managed by the pool. This reduces memory fragmentation and improves cache locality since related structures are allocated contiguously.

**Partial clone optimization** benefits from ORT's careful tree traversal. By skipping unchanged directories and avoiding redundant tree walks, ORT minimizes the number of tree objects that must be fetched. For users with partial clones (repositories where not all objects are initially present), this reduces network round trips substantially. The basename prefetching optimization further helps by fetching only blob objects for files with matching basenames before attempting full inexact rename detection.

## Performance characteristics and real-world impact

ORT's performance improvements stem from algorithmic efficiency rather than micro-optimizations, delivering consistent speedups across diverse repositories and merge scenarios.

**Benchmark results** from Elijah Newren's testing using synthetic testcases demonstrate the performance envelope. The few-renames testcase (moderate rename activity) improved from 18.912 seconds with recursive to 198.3 milliseconds with ORT, representing a 95x speedup. The mega-renames testcase (extreme rename activity) improved from 5,964 seconds to 661.8 milliseconds, achieving a 9,012x speedup. The just-one-mega testcase (single large merge) went from 149.6 seconds to 264.6 milliseconds, a 565x speedup. These results show ORT excels particularly in rename-heavy scenarios where recursive's inefficiencies compound.

**Real-world deployment** at GitHub validates the benchmarks with production data. When GitHub switched their github/github monorepo to ORT in September 2022, they measured 10x speedup in both average and P99 merge cases. Across all GitHub merges, the P50 latency improved 10x while P99 improved 5x. A rebase experiment that took 2.56 hours with the old method completed in under 10 minutes with ORT. Extrapolating their measurements suggested a workload requiring 512 hours with their previous libgit2-based approach would complete in 33 hours with ORT, enabling new automation workflows previously considered infeasible.

**Consistency improvements** may be even more valuable than raw speed for user experience. Recursive merge exhibited high performance variance with occasional catastrophically slow merges when pathological rename patterns occurred. Users would experience seemingly random multi-minute hangs during routine operations. ORT demonstrates low variance performance, delivering consistently fast merges regardless of rename patterns. This predictability improves developer productivity by eliminating unexpected delays.

**Resource utilization** benefits from ORT's in-memory design. By avoiding repeated index file writes and working tree updates during the merge process, ORT reduces I/O overhead substantially. Memory usage is lower per operation despite maintaining richer data structures, because the memory pool allocation pattern matches object lifetimes perfectly. CPU utilization improves through better cache locality (related objects allocated contiguously) and reduced system call overhead (fewer malloc/free operations).

**Scalability characteristics** show ORT maintaining performance advantages as repository size grows. The O(1) path lookup through strmap means adding more files has minimal impact on per-file processing time. The deferred directory traversal optimization becomes increasingly valuable in large repositories where unchanged subtrees can be resolved without examining thousands of files. The rename detection caching provides compounding benefits during rebases, where the advantages multiply with each sequential merge operation.

## Conclusion

Git's ORT merge strategy represents a fundamental reimagining of merge algorithms, demonstrating how careful architectural design can yield both dramatic performance improvements and enhanced correctness in mature software systems. By separating merge computation from filesystem updates and building a complete in-memory representation before processing, ORT achieves 500-9000x speedups over the recursive strategy while fixing long-standing edge case bugs.

The implementation's sophistication lies in its data structure choices and algorithmic optimizations. The strmap-based paths tracking enables O(1) lookups, memory pools reduce allocation overhead by 10-100x, deferred directory traversal avoids unnecessary recursion, and rename detection caching delivers multiplicative benefits for sequential operations. The conflict_info structure with its filemask, dirmask, and match_mask bit fields provides rich conflict tracking in minimal space.

Beyond performance, ORT enables new capabilities impossible with recursive merge. The in-memory operation model facilitates server-side merges without working directories, enabling GitHub and other platforms to perform merge testing without expensive checkout operations. The AUTO_MERGE reference and deferred conflict message generation improve user experience. The clean separation between merge computation and filesystem updates makes the codebase more maintainable and extensible.

The transition from recursive to ORT occurred rapidly once the implementation proved itself, with adoption in Git 2.34 (November 2021) and GitHub production deployment in September 2022. This quick adoption reflects the transparent nature of the improvement—users gain massive performance benefits without changing workflows or learning new concepts. The recursive strategy is now deprecated with its command-line option redirecting to ORT.

For developers working with large repositories or rename-heavy workflows, ORT's impact cannot be overstated. Operations that previously took minutes now complete in milliseconds. Rebases that were overnight batch jobs become interactive workflows. The performance consistency eliminates the anxiety of unpredictable merge delays. These improvements compound to enable new development practices, from more frequent integration to automated merge testing at scale.

The ORT implementation in merge-ort.c stands as a masterclass in algorithm design, demonstrating that even well-optimized existing systems can benefit from fundamental architectural rethinking. Its success validates the investment in comprehensive rewrites when architectural limitations constrain both performance and correctness.

https://github.com/newren/how-merge-works/blob/master/how-merge-works.tex
